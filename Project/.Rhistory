result <- data.frame(num=1:length(train_pc$sdev),
ex=varex,
cum=varcum)
plot(result$num,result$cum,type="b",xlim=c(0,100),
main="Variance Explained by Top 100 Components",
xlab="Number of Components",ylab="Variance Explained")
abline(v=25,lty=2)
train_score <- as.matrix(train) %*% train_pc$rotation[,1:10]
train <- cbind(label,as.data.frame(train_score))
colors <- rainbow(length(unique(train$label)))
names(colors) <- unique(train$label)
plot(train$PC1,train$PC2,type="n",main="First Two Principal Components")
text(train$PC1,train$PC2,label=train$label,col=colors[train$label])
set.seed(1492)
grid <- expand.grid(sigma = c(.2),
C = c(2)
)
svm_mdl <- train(label~.,data=train,
method="svmRadial",
trControl=trainControl(method="cv",
number=10),
tuneGrid=grid)
svm_mdl
svm_mdl$Accuracy
str(svm_mdl)
mean(svm_mdl$resample[1,])
mean(svm_mdl$resample)
svm_mdl$resample
svm_mdl$resample[1,]
svm_mdl$resample[,1]
mean(svm_mdl$resample[,1])
getBestComponents <- function(){
acc_in <- rep(0, 20)
acc_out <- rep(0,20)
for( i in 2:20 ){
train <- data[sample,]
test <- data[-sample,]
nzr <- nearZeroVar(train[,-1],saveMetrics=T,freqCut=10000/1,uniqueCut=1/7)
cutvar <- rownames(nzr[nzr$nzv==TRUE,])
var <- setdiff(names(train),cutvar)
train <- train[,var]
label <- as.factor(train[[1]])
train$Digit <- NULL
train <- train/255
covtrain <- cov(train)
train_pc <- prcomp(covtrain)
varex <- train_pc$sdev^2/sum(train_pc$sdev^2)
varcum <- cumsum(varex)
result <- data.frame(num=1:length(train_pc$sdev),
ex=varex,
cum=varcum)
train_score <- as.matrix(train) %*% train_pc$rotation[,1:i]
train <- cbind(label,as.data.frame(train_score))
set.seed(1492)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.015),
C = c(1)
)
svm_mdl <- train(label~.,data=train,
method="svmRadial",
trControl=trainControl(method="cv",
number=10),
tuneGrid=grid)
label_test <- test$Digit
test <- test[,var[-1]]/255
test <- as.matrix(test) %*% train_pc$rotation[,1:i]
test <- as.data.frame(test)
pred <- predict(svm_mdl$finalModel,test,type="response")
prediction <- data.frame(ImageId=1:nrow(test),Label=pred)
confusionMatrix(pred, label_test)
pred_train <- predict(svm_mdl$finalModel,train_score,type="response")
confusionMatrix(pred_train, label)
acc_in[i] <- confusionMatrix(pred_train, label)$overall[1]
acc_out[i] <- mean(svm_mdl$resample[,1])
print(i)
}
write.table(acc_ins, sprintf("data/acc_in.csv"), col.names=FALSE,row.names=FALSE, sep=",", append=F)
write.table(acc_out, sprintf("data/acc_out.csv"), col.names=FALSE,row.names=FALSE, sep=",", append=F)
}
getBestComponents()
acc_in
getBestComponents <- function(){
acc_in <- rep(0, 20)
acc_out <- rep(0,20)
for( i in 2:20 ){
train <- data[sample,]
test <- data[-sample,]
nzr <- nearZeroVar(train[,-1],saveMetrics=T,freqCut=10000/1,uniqueCut=1/7)
cutvar <- rownames(nzr[nzr$nzv==TRUE,])
var <- setdiff(names(train),cutvar)
train <- train[,var]
label <- as.factor(train[[1]])
train$Digit <- NULL
train <- train/255
covtrain <- cov(train)
train_pc <- prcomp(covtrain)
varex <- train_pc$sdev^2/sum(train_pc$sdev^2)
varcum <- cumsum(varex)
result <- data.frame(num=1:length(train_pc$sdev),
ex=varex,
cum=varcum)
train_score <- as.matrix(train) %*% train_pc$rotation[,1:i]
train <- cbind(label,as.data.frame(train_score))
set.seed(1492)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.015),
C = c(1)
)
svm_mdl <- train(label~.,data=train,
method="svmRadial",
trControl=trainControl(method="cv",
number=10),
tuneGrid=grid)
label_test <- test$Digit
test <- test[,var[-1]]/255
test <- as.matrix(test) %*% train_pc$rotation[,1:i]
test <- as.data.frame(test)
pred <- predict(svm_mdl$finalModel,test,type="response")
prediction <- data.frame(ImageId=1:nrow(test),Label=pred)
confusionMatrix(pred, label_test)
pred_train <- predict(svm_mdl$finalModel,train_score,type="response")
confusionMatrix(pred_train, label)
acc_in[i] <- confusionMatrix(pred_train, label)$overall[1]
acc_out[i] <- mean(svm_mdl$resample[,1])
print(i)
}
write.table(acc_in, sprintf("data/acc_in.csv"), col.names=FALSE,row.names=FALSE, sep=",", append=F)
write.table(acc_out, sprintf("data/acc_out.csv"), col.names=FALSE,row.names=FALSE, sep=",", append=F)
}
acc_in
getBestComponents()
rm(list=ls())
require(EBImage)
install.packages("EBImage")
source("http://bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R")
biocLite("EBImage")
library(EBImage)
install.packages("EBImage")
rm(list=ls())
library(mxnet)
library(caret)
acc <- rep(0, 10)
rounds <- c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
sample <- sample(nrow(input)*0.8)
train <- input[sample,]/255
test <- input[-sample,]/255
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
sample <- sample(nrow(input)*0.8)
train <- input[sample,]
test <- input[-sample,]
tran[-1]/255
train[-1]/255
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
sample <- sample(nrow(input)*0.8)
train <- input[sample,]
test <- input[-sample,]
train <- train[-1]/255
test <- test[-1]/255
train
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
label <- input$Digit
input$Digit <- NULL
input <- input/255
input$Digit <- label
input$Digit <- as.factor(input$Digit)
sample <- sample(nrow(input)*0.8)
train <- input[sample,]
test <- input[-sample,]
train <- data.matrix(train)
train_x <- t(train[, -1])
train_y <- train[, 1]
train_array <- train_x
dim(train_array) <- c(28, 28, 1, ncol(train_x))
test_x <- t(test[, -1])
test_y <- test[, 1]
test_array <- test_x
dim(test_array) <- c(28, 28, 1, ncol(test_x))
data <- mx.symbol.Variable('data')
conv_1 <- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 20)
tanh_1 <- mx.symbol.Activation(data = conv_1, act_type = "tanh")
pool_1 <- mx.symbol.Pooling(data = tanh_1, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))
conv_2 <- mx.symbol.Convolution(data = pool_1, kernel = c(5, 5), num_filter = 50)
tanh_2 <- mx.symbol.Activation(data = conv_2, act_type = "tanh")
pool_2 <- mx.symbol.Pooling(data=tanh_2, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))
flatten <- mx.symbol.Flatten(data = pool_2)
fc_1 <- mx.symbol.FullyConnected(data = flatten, num_hidden = 500)
tanh_3 <- mx.symbol.Activation(data = fc_1, act_type = "tanh")
fc_2 <- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 40)
NN_model <- mx.symbol.SoftmaxOutput(data = fc_2)
mx.set.seed(100)
devices <- mx.cpu()
model <- mx.model.FeedForward.create(NN_model,
X = train_array,
y = train_y,
ctx = devices,
num.round = 50,
array.batch.size = 50,
learning.rate = 0.01,
momentum = 0.9,
eval.metric = mx.metric.accuracy,
epoch.end.callback = mx.callback.log.train.metric(100))
model <- mx.model.FeedForward.create(NN_model,
X = train_array,
y = train_y,
ctx = devices,
num.round = 5,
array.batch.size = 50,
learning.rate = 0.01,
momentum = 0.9,
eval.metric = mx.metric.accuracy,
epoch.end.callback = mx.callback.log.train.metric(100))
predicted <- predict(model, test_array)
model
test_array
predicted <- predict(model, test_array)
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
label <- input$Digit
input$Digit <- NULL
input$Digit <- label
input$Digit <- as.factor(input$Digit)
sample <- sample(nrow(input)*0.8)
train <- input[sample,]
test <- input[-sample,]
train <- data.matrix(train)
train_x <- t(train[, -1])
train_y <- train[, 1]
train_array <- train_x
dim(train_array) <- c(28, 28, 1, ncol(train_x))
test_x <- t(test[, -1])
test_y <- test[, 1]
test_array <- test_x
dim(test_array) <- c(28, 28, 1, ncol(test_x))
data <- mx.symbol.Variable('data')
conv_1 <- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 20)
tanh_1 <- mx.symbol.Activation(data = conv_1, act_type = "tanh")
pool_1 <- mx.symbol.Pooling(data = tanh_1, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))
conv_2 <- mx.symbol.Convolution(data = pool_1, kernel = c(5, 5), num_filter = 50)
tanh_2 <- mx.symbol.Activation(data = conv_2, act_type = "tanh")
pool_2 <- mx.symbol.Pooling(data=tanh_2, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))
flatten <- mx.symbol.Flatten(data = pool_2)
fc_1 <- mx.symbol.FullyConnected(data = flatten, num_hidden = 500)
tanh_3 <- mx.symbol.Activation(data = fc_1, act_type = "tanh")
fc_2 <- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 40)
NN_model <- mx.symbol.SoftmaxOutput(data = fc_2)
mx.set.seed(100)
devices <- mx.cpu()
model <- mx.model.FeedForward.create(NN_model,
X = train_array,
y = train_y,
ctx = devices,
num.round = 5,
array.batch.size = 50,
learning.rate = 0.01,
momentum = 0.9,
eval.metric = mx.metric.accuracy,
epoch.end.callback = mx.callback.log.train.metric(100))
predicted <- predict(model, test_array)
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
sample <- sample(nrow(input)*0.8)
train <- input[sample,]
test <- input[-sample,]
train <- data.matrix(train)
train_x <- t(train[, -1])
train_y <- train[, 1]
train_array <- train_x
dim(train_array) <- c(28, 28, 1, ncol(train_x))
test_x <- t(test[, -1])
test_y <- test[, 1]
test_array <- test_x
dim(test_array) <- c(28, 28, 1, ncol(test_x))
data <- mx.symbol.Variable('data')
conv_1 <- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 20)
tanh_1 <- mx.symbol.Activation(data = conv_1, act_type = "tanh")
pool_1 <- mx.symbol.Pooling(data = tanh_1, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))
conv_2 <- mx.symbol.Convolution(data = pool_1, kernel = c(5, 5), num_filter = 50)
tanh_2 <- mx.symbol.Activation(data = conv_2, act_type = "tanh")
pool_2 <- mx.symbol.Pooling(data=tanh_2, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))
flatten <- mx.symbol.Flatten(data = pool_2)
fc_1 <- mx.symbol.FullyConnected(data = flatten, num_hidden = 500)
tanh_3 <- mx.symbol.Activation(data = fc_1, act_type = "tanh")
fc_2 <- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 40)
NN_model <- mx.symbol.SoftmaxOutput(data = fc_2)
mx.set.seed(100)
devices <- mx.cpu()
model <- mx.model.FeedForward.create(NN_model,
X = train_array,
y = train_y,
ctx = devices,
num.round = 5,
array.batch.size = 50,
learning.rate = 0.01,
momentum = 0.9,
eval.metric = mx.metric.accuracy,
epoch.end.callback = mx.callback.log.train.metric(100))
predicted <- predict(model, test_array)
predicted_labels <- max.col(t(predicted)) - 2
table(test$Digit, predicted_labels)
sum(diag(table(test[, 1], predicted_labels)))/500
makeConfusionMatrix <- function(pred, true){
mod <- confusionMatrix(pred,true)
confM <- mod$table
confM <- rbind(confM, Totals = rowSums(confM))
sums <- rowSums(confM)
confM <- cbind(confM, Error = 0)
for (row in 1:(nrow(confM)-1)){
correct <- confM[row,row]
wrong <- sums[row] - confM[row,row]
confM[row,"Error"] = round(wrong/(correct+wrong),5)
}
confM[nrow(confM), "Error"] <- 1 - mod$overall["Accuracy"]
return(confM)
}
train[2:ncol(train)] <- train[2:ncol(train)]/255
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
sample <- sample(nrow(input)*0.8)
train <- input[sample,]
test <- input[-sample,]
train[2:ncol(train)] <- train[2:ncol(train)]/255
test[2:ncol(test)] <- test[2:ncol(test)]/255
train <- data.matrix(train)
train_x <- t(train[, -1])
train_y <- train[, 1]
train_array <- train_x
dim(train_array) <- c(28, 28, 1, ncol(train_x))
test_x <- t(test[, -1])
test_y <- test[, 1]
test_array <- test_x
dim(test_array) <- c(28, 28, 1, ncol(test_x))
data <- mx.symbol.Variable('data')
conv_1 <- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 20)
tanh_1 <- mx.symbol.Activation(data = conv_1, act_type = "tanh")
pool_1 <- mx.symbol.Pooling(data = tanh_1, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))
conv_2 <- mx.symbol.Convolution(data = pool_1, kernel = c(5, 5), num_filter = 50)
tanh_2 <- mx.symbol.Activation(data = conv_2, act_type = "tanh")
pool_2 <- mx.symbol.Pooling(data=tanh_2, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))
flatten <- mx.symbol.Flatten(data = pool_2)
fc_1 <- mx.symbol.FullyConnected(data = flatten, num_hidden = 500)
tanh_3 <- mx.symbol.Activation(data = fc_1, act_type = "tanh")
fc_2 <- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 40)
NN_model <- mx.symbol.SoftmaxOutput(data = fc_2)
mx.set.seed(100)
devices <- mx.cpu()
model <- mx.model.FeedForward.create(NN_model,
X = train_array,
y = train_y,
ctx = devices,
num.round = 5,
array.batch.size = 50,
learning.rate = 0.01,
momentum = 0.9,
eval.metric = mx.metric.accuracy,
epoch.end.callback = mx.callback.log.train.metric(100))
predicted <- predict(model, test_array)
predicted_labels <- max.col(t(predicted)) - 2
table(test$Digit, predicted_labels)
sum(diag(table(test[, 1], predicted_labels)))/500
input
t(input)
trans <- t(input[2:ncol(input)])
trans <- cbind(input$Digit, trans)
trans <- t(t(input[2:ncol(input)]))
trans <- cbind(input$Digit, trans)
rotate <- function(x) t(apply(x, 2, rev))
trans <- rotate(input[2:ncol(input)])
trans <- cbind(input$Digit, trans)
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
rotate <- function(x) t(apply(x, 2, rev))
trans <- rotate(input[2:ncol(input)])
nrow(trans)
ncol(trnas)
ncol(trans)
trans <- rotate(rotate(input[2:ncol(input)]))
nrow(trans)
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
rotate <- function(x) t(apply(x, 2, rev))
trans <- rotate(rotate(input[2:ncol(input)]))
t <- cbind(input$Digit, trans)
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
rotate <- function(x) t(apply(x, 2, rev))
trans <- rotate(rotate(input[2:ncol(input)]))
t <- cbind(input$Digit, trans)
input <- rbind(input, t)
t
input
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
rotate <- function(x) t(apply(x, 2, rev))
trans <- rotate(rotate(input[2:ncol(input)]))
t <- cbind(input$Digit, trans)
names(t) <- rev(colnames(t))
t
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
rotate <- function(x) t(apply(x, 2, rev))
trans <- rotate(rotate(input[2:ncol(input)]))
typeof(input)
typeof(t)
t
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
rotate <- function(x) t(apply(x, 2, rev))
trans <- rotate(rotate(input[2:ncol(input)]))
t <- cbind(input$Digit, trans)
t
ncol(t)
t$Digit
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
rotate <- function(x) t(apply(x, 2, rev))
trans <- rotate(rotate(input[2:ncol(input)]))
t <- rbind(input$Digit, trans)
rm(list=ls())
library(mxnet)
library(caret)
set.seed(69)
input <- read.csv("Train_Digits_20171108.csv")
input$Digit <- input$Digit%%2
input$Digit <- as.factor(input$Digit)
rotate <- function(x) t(apply(x, 2, rev))
trans <- rotate(rotate(input[2:ncol(input)]))
t <- cbind(input$Digit, trans)
sample <- sample(nrow(input)*0.8)
train <- input[sample,]
test <- input[-sample,]
train <- data.matrix(train)
train_x <- t(train[, -1])
train_y <- train[, 1]
train_array <- train_x
dim(train_array) <- c(28, 28, 1, ncol(train_x))
test_x <- t(test[, -1])
test_y <- test[, 1]
test_array <- test_x
dim(test_array) <- c(28, 28, 1, ncol(test_x))
data <- mx.symbol.Variable('data')
conv_1 <- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 20)
